import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout
import instaloader
from tensorflow.keras.models import save_model
import joblib

train_path = '/content/train.csv'
test_path = '/content/test.csv'
train = pd.read_csv(train_path)
test = pd.read_csv(test_path)

x_train = train.iloc[:, :-1].values
y_train = train.iloc[:, -1].values
x_test = test.iloc[:, :-1].values
y_test = test.iloc[:, -1].values

np.save('x_train.npy', x_train)
np.save('y_train.npy', y_train)

sc = StandardScaler()
x_train_sc = sc.fit_transform(x_train)
x_test_sc = sc.transform(x_test)

pca = PCA(n_components=2)
x_train_sc_pca = pca.fit_transform(x_train_sc)
x_test_sc_pca = pca.transform(x_test_sc)

losreg = LogisticRegression(random_state=7)
losreg.fit(x_train_sc_pca, y_train)
y_pred = losreg.predict(x_test_sc_pca)
print("Logistic Regression Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

knn = KNeighborsClassifier(n_neighbors=9, metric='minkowski', p=2)
knn.fit(x_train_sc, y_train)
y_pred = knn.predict(x_test_sc)
print("K-Nearest Neighbors Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

svc = SVC(kernel='rbf', random_state=5)
svc.fit(x_train_sc, y_train)
y_pred = svc.predict(x_test_sc)
print("Support Vector Machine Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

dtc = DecisionTreeClassifier(criterion='entropy', random_state=0)
dtc.fit(x_train_sc, y_train)
y_pred = dtc.predict(x_test_sc)
print("Decision Tree Classifier Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

rfc = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)
rfc.fit(x_train_sc, y_train)
y_pred = rfc.predict(x_test_sc)
print("Random Forest Classifier Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

username = input("Enter Username: ")
profile = instaloader.Profile.from_username(instaloader.Instaloader().context, username)

profile_data = {
    'profile_pic': 1 if profile.profile_pic_url else 0,
    'num_by_num': sum(char.isdigit() for char in profile.username) / len(profile.username.split()),
    'full_name': len(profile.full_name.split()),
    'num_by_char': sum(char.isdigit() for char in profile.full_name) / len(profile.full_name),
    'name_username': 1 if profile.full_name.lower() == profile.username.lower() else 0,
    'bio_len': len(profile.biography),
    'url': 1 if profile.external_url else 0,
    'private': 1 if profile.is_private else 0,
    'post': profile.mediacount,
    'followers': profile.followers,
    'follows': profile.followees,
}

user_input = np.array([[
    profile_data['profile_pic'],
    profile_data['num_by_num'],
    profile_data['full_name'],
    profile_data['num_by_char'],
    profile_data['name_username'],
    profile_data['bio_len'],
    profile_data['url'],
    profile_data['private'],
    profile_data['post'],
    profile_data['followers'],
    profile_data['follows']
]])

user_input_scaled = sc.transform(user_input)
prediction = rfc.predict(user_input_scaled)
prob = rfc.predict_proba(user_input_scaled)

if prediction == 0:
    print('0: Genuine account')
else:
    print('1: Spam account')

prob_percentage = prob[:, prediction] * 100
percentage_value = prob_percentage.item()
print('Probability: {:.0f}%'.format(percentage_value))

joblib.dump(rfc, '/content/mrfc.pkl')

param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'linear', 'poly']
}

svc = SVC()
grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(x_train_sc, y_train)
print("Best parameters found: ", grid_search.best_params_)
print("Best score found: ", grid_search.best_score_)